# seq2seq-model-using-attention-
Sequence to sequence model for different tasks like machine translation, summarization, question answering, etc using attention layer implementation.
